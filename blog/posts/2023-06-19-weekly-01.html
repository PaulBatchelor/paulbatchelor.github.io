<!DOCTYPE html>
<html lang="en">
<head>

<meta charset="utf-8">
<meta name="viewport" content="width=device-width", initial-scale=1>
<title>Weekly Update 1</title>

<link rel="stylesheet" href="/css/style.css">

</head>
<body>
<div id="main">
<h1>Weekly Update 1</h1>
<p>2023-06-19</p>
<p>This week, I found myself implementing Glottal pulsed noise (a thing
used in my singing synthesizer), completed
my <a href="/gestlings/protogestling_mockup">Proto-gestling</a> (proof
of concept for my <a href="/wiki/gestlings">Gestlings</a> project), and
thought about a concept in game development that I'm calling
"asset-driven development".</p>
<h2>Making my Computer Sing Better</h2>
<p>To begin, here's a little melody I wrote, being performed by a singer I
also built. I'll talk about this some more.</p>
<p><audio controls>
<source src="/res/weekly/singing_glottal_pulsed_noise.ogg" type="audio/ogg">
</audio>
</p>
<p>One of my ongoing fascinations over many years has been in building
singing synthesizers like this one. There is <a href="https://en.wikipedia.org/wiki/Uncanny_valley">a strange (and sometimes
unsettling) familiarity</a> that begins to happen when computers start
to imitate human vocalizations. As a computer music composer, I
find this adds a great dimension of accessibility to works. You
don't have to understand all the jargon in the liner notes when a
talky computer music piece is framed as a
<a href="https://www.youtube.com/watch?v=Qi6vn2aNew0">computer on the phone with his mother</a>. This idea
of giving inanimate objects human-like
qualities, known as anthropomorphization, is a big
<a href="/wiki/anthrosound">area of focus</a> for me.</p>
<p>There's are many little components that go into making a computer
sing like the sample above, from building the singer, to telling
the singer what to perform and how to perform it. This week, I
focused on improving the "singer" by upgrading a component using
something called "pitch-synchronous pulsed noise"<a href="/brain/PRC_dissertation">link1</a> <a href="/brain/glottal_flow_derivative">link2</a> <a href="/brain/glottal_source_modelling">link3</a>. The singers I
make are built up <a href="https://ccrma.stanford.edu/~jos/pasp/Singing_Kelly_Lochbaum_Vocal_Tract.html">using</a>,
<a href="https://en.wikibooks.org/wiki/Engineering_Acoustics/source-filter_theory">math</a>.
and this I found to be slightly better sounding math.</p>
<p>Before I break down what "pitch-synchronous pulsed noise" is, some
orientation about where it goes is needed. Building a virtual singer
inside a computer typically involves two parts: a <a href="/sndkit/tract">vocal tract</a>, which
is essentially a tube, and some kind of air flow that goes through
the tract to produce vocal sound at the other end. This "air flow",
produced by something called a <a href="/sndkit/glottis">glottis</a>, is what gives us the initial
pitched sound. When it goes through the tract, this sound is shaped
and what comes out the other end sounds vocally. We'll be focusing
in on this sound-making component.</p>
<p>This thing I'm calling "Pitch Synchronous Pulsed Noise", what it
does is add a little detail to the thing that goes into our digitally
constructed vocal tract. "pitch-synchrounous" is a fancy way of
saying "thing that is aligned with pitch of the voice". When the
pitch goes up or down, this thing changes with it. In fact, it is
"glued" to the rest of this component, totally locked in step with
the underlying sound waveform. The "pulsed noise" bit just means
"small noise bursts". In <a href="/brain/PRC_dissertation">1991, Perry Cook observed these small noise
bursts</a> when looking at recordings of actual singingers.
This attempts to approximate those noise bursts. The end result is a singing sound
that is a bit more "breathy" and naturalistic.</p>
<h2>Building a "Proto-Gestling"</h2>
<p>The <a href="/gestlings/protogestling">Proto-Gestling</a> is the Gestling before the Gestling, for an
ongoing project of mine called "Gestlings". The core goal of this
project is to build sounds that talk about themselves. To get even
close to this place, there was a lot of tooling that needed to be
build. In order for a Gestling to talk about themselves, they need
a mouth. A mouth is part of a physiology that makes sound. The sound
being produced is structured to be some kind of pseudo-language
performed on this invented creature physiology. This pseudo-language
gibberish is composed of smaller bits that are glued together. And
oh yeah, the mouth is part of face which should be expressive. And
you need to have some kind of captioning system if you want an
audience to  understand this organized gibberish.</p>
<p>All of this had to be made from scratch, which includes a sophisticated
audio engine to constuct the "speech" engine (what I sometimes call
"speeched music"), as well as a very crude graphics pipeline capable
of producing video. Both the sound and video had to be coordinated
in order to get face movements to work.</p>
<p>The end result looks like this:</p>
<p><video controls>
<source src="/gestlings/res/protogestling.mp4" type="video/mp4">
</video>
</p>
<p>It's a lot of work for one short video. A very silly one at that.
But, what it conveys, the sliver of a sliver of a whisp of a critter
with a personality, is far greater than the sum of its parts. This,
to me, is worth <a href="/gestlings/protogestling_mockup">all the code flung at it</a>. I think.</p>
<h2>Asset Driven Development</h2>
<p>When I say asset-driven development, I am referring to the way games
are usually designed. There is a clear division between the "art"
of the video game known as asssets (textures, sound, etc), and the
game logic, sometimes known as the engine.</p>
<p>As someone who has attempted to approach "code" as art for my entire
adult life, I find my self conflicted by this approach. The division
feels arbitrary. A good use of the computer medium for creative
pursuits <em>should</em> blur the line between program logic and "art",
as they are one in the same. But, recently, in working on Gestlings,
I've been seeing the benefits. A lot of stuff <em>does</em> end up basically
being essentially dumb data, which is what an assset is. Assets are
much easier manage than code. They don't change as much. You can
write programs to generate assets, and programs to take those assets
and make assets. You can write new code to handle those assets.
Your assets will outlive your code.</p>
<p>Anyways, enough of all that. Until next time.</p>

</div>
</body>
</html>
