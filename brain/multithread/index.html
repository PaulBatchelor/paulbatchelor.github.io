<!DOCTYPE html>
<html lang="en">
<head>

<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<link rel="stylesheet" href="/brain/css/style.css">

</head>
<body>
<div id="main">
<title>Multi-threaded Topics</title>
<h1>Multi-threaded Topics</h1>
<p>Miscellaneous topics of things related to multi-threaded
programming.
</p>

<h2>Deadlock</h2>

<p>A situation that occurs in a multi-threaded system when
a group threads are completely blocked because they
depend on another member in the group.
</p>

<h2>Race Condition</h2>

<p>Occurs in a program when threads are required to work
in a specific sequential order.
</p>
<p>Depedendency on controlling the timing of events that
are uncontrollable.
</p>

<h2>Atomic Operations</h2>

<p>Concurrent programming is made possible with the use
of a handful of hardware-specific atomic operations.
</p>
<p>Atomicity of the instructions ensures that the
operation happens without interuption.
</p>
<p>Compare and Swap (CAP) is the most common operation.
It will look at the contents of a memory address, compare
it to a given value, and if they match, update (swap) the
value with a provided new value.
</p>

<h2>Lock-Free Data Structures</h2>

<p>A reminder that lock-free means that no thread is able
to completely lock up the system and prevent other
threads from working. Threads can still starve or stall.
</p>
<p>A common lock-free data structure is the lock-free cue.
</p>
<p>Here it is as a linked list:
</p>
<p><a href="https://en.wikipedia.org/wiki/Non-blocking_linked_list">https://en.wikipedia.org/wiki/Non-blocking_linked_list</a>.
</p>
<p>It basically works like a typical linked list, except
that it uses CAS for insertion and deletion.
</p>
<p>More information on non-blocking algorithms can be found
here:
</p>
<p><a href="https://en.wikipedia.org/wiki/Non-blocking_algorithm">https://en.wikipedia.org/wiki/Non-blocking_algorithm</a>.
</p>

<h2>Spin Lock</h2>

<p>This is a kind of lock that continuously checks and
requests access to a resource and waits ("spins") for
a turn. Once accessed, it will
lock, perform it's operations on the data, then release
the lock.
</p>
<p>Linus Torvalds refers to spinlcoks as a
"mutal exclusion mechanism".
</p>
<p>Spinlocks are reasonably simple to implement, and can
be fairly efficient, provided that the critical sections
of code are small.
</p>

<h2>Semaphore</h2>

<p>A data type that is used to control access to a particular
resource.
</p>
<p>A binary semaphore implements the basic kind of mutex.
</p>
<p>A counting semaphore can be thought of as a kind
of throttling (eg: limiting logins to a particular server).
</p>
<p>Linux Torvalds discussing Semaphores on the Mailing List.
Linux talking about semaphores, spinlocks, and mutexes
were clear to read:
</p>
<p><a href="https://www.yarchive.net/comp/linux/semaphores.html">https://www.yarchive.net/comp/linux/semaphores.html</a>* Mutex
A "mutal exclusion", more generally referred to as a
"lock", is a primative that limits access to a particular
resources when there are many threads of execution.
</p>
<p>The wikipedia page is a tremendous resource on locks,
with links to other topics related to concurrent
programming:
</p>
<p><a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">https://en.wikipedia.org/wiki/Lock_(computer_science)</a>.
</p>

<h2>"volatile" in the context of multithreading</h2>

<p>In C/C++ the volatile keyword indicates that the
memory in question is constantly changing, even if it
isn't apparent from local code. This can be used as a hint
for optimizing compilers to not accidentally optimize
reads/writes, and will more explicitely access more
up-to-date variables.
</p>
<p>The wikipedia very explicitely says that volatile should
NOT be used in the context of shared data between
threads and inter-thread communication, which probably
means at one point people <b>were</b> using for just that.
</p>

<h2>Messages</h2>

<p>Anything tagged with the <code>multithread</code> group will
show up here.
</p>
<p><b>[ada6136b] 2022-06-03-20-32</b>: Communicating Sequential Processes. <a href="https://en.m.wikipedia.org/wiki/Communicating_sequential_processes">https://en.m.wikipedia.org/wiki/Communicating_sequential_processes</a> 
</p>
<p><b>[6bd3d3bc] 2022-06-03-20-32</b>: A lock-free, concurrent, generic queue in 32 bits https://nullprogram.com/blog/2022/05/14/ 
</p>
<p><b>[7027165b] 2022-03-22-06-25</b>: mutex: an abbreviation for mutal exclusion. allows only one thread to access some data at any given time.
</p>
<p><b>[24520f46] 2022-03-22-06-23</b>: "do not communicate by sharing memory. share memory by communicating". this is a go motto, quoted in the rust book.
</p>
<p><b>[3afb8826] 2022-03-21-09-42</b>: green thread: threads that are provided by the programming language, rather than through the OS API.
</p>
<p><b>[98e7c2a9] 2022-03-21-09-35</b>: Turning concurrency runtime errors into compiler errors was a big part of the original design ethos of Rust.
</p>
<p><b>[5216f541] 2022-03-21-09-33</b>: safe concurrency is such a big part of Rust's goals. Concurrency is nearly the polar opposite of what I typically work on and think about, so this will probably be a new headspace for me.
</p>
<p><b>[f8935888] 2022-03-19-10-44</b>: a good practical resource page on threads, but in the context of audio: <a href="mu.kj.st/ctrl">mu.kj.st/ctrl</a>.
</p>
<p><b>[55719f78] 2022-03-17-14-55</b>: ABA problem: a problem that occurs in multithreaded computing, when a location is read twice, has the same value for both reads, and "value is the same" indicates "nothing has changed". Meanwhile, in between reads, another thread can change that value, do work, and change the value back, thus meaning that things <b>have</b> changed.
</p>
<p><b>[c3a9ba06] 2022-03-17-14-36</b>: race condition: a situation that arises when a computer program, to operate properly, depends on the sequence or timing of the program's threads.
</p>
<p><b>[bd20d448] 2022-03-17-10-53</b>: according the C++ standard, volatile is only to be used for hardware access. For interthread communication, use std::atomic<T> templates.
</p>
<p><b>[70febbf8] 2022-03-17-10-52</b>: in C, volatile is probably the closest way to do inter-thread communication without atomics.
</p>
<p><b>[ffac70bf] 2022-03-17-10-51</b>: volatile seems to be used when state is being manipulated as a global variable (calling this memory mapped I/O).
</p>
<p><b>[0b274c1d] 2022-03-17-10-49</b>: to add onto this, I suppose then volatile keywords could be used to implement a lock that isn't guaranteed to work all the time.
</p>
<p><b>[ebd8b338] 2022-03-17-10-48</b>: the use of volatile variables in C/C++ is apparently highly discouraged as a synchronization method in concurrent/multithreaded programming. they are not thread-safe in the vast majority of implementations.
</p>
<p><b>[dd6e66f7] 2022-03-17-10-42</b>: turns out there's a lot of great information on the wikipedia page on locking: <a href="https://en.wikipedia.org/wiki/Lock_(computer_science)">https://en.wikipedia.org/wiki/Lock_(computer_science)</a>.
</p>
<p><b>[cab30ada] 2022-03-17-10-28</b>: Barrier: in parallel computing, a barrier is a type of synchronization method. A barrier for a group of threads or processes in the source code means any thread/process must stop at this point and cannot proceed until all other thread/processes reach this barrier.
</p>
<p><b>[bcf8c5d1] 2022-03-17-10-24</b>: Funnel: a synchronization primitive used in kernel development to protect system resources. It is a mutex mechanism that prevents more than one thread from accessing certain kernel resources at the same time.
</p>
<p><b>[c6239fa2] 2022-03-17-10-22</b>: priority inversion: a scenario in scheduling in which a high priority task is indirectly superseded by a lower priority task, effectively inverting the assigned priorities of the tasks.
</p>
<p><b>[b1d0e53a] 2022-03-17-10-19</b>: software transactional memory (STM): a concurrency control mechanism analogous to database transactions for controlling access to shared memory in concurrent computing. It is an alternative to lock-based synchronization.
</p>
<p><b>[eef4dad1] 2022-03-17-10-18</b>: optimistic concurrency control: also known as optimistic locking. a concurrency control method applied to transactional systems such as relational database systems and software transactional memory.
</p>
<p><b>[e43538be] 2022-03-17-10-16</b>: 2-phase locking: a concurrency method that guarantees serializability. Abbreviated 2PL. Used in the context of database transactions, 2PL consists of two distinct, consecutive phases: expanding (growing), and shrinking (contracting).
</p>
<p><b>[844dd538] 2022-03-17-10-12</b>: a record lock is also known as a database lock.
</p>
<p><b>[6fad809f] 2022-03-17-10-07</b>: record locking: the technique of preventing simultaneous access to data in a database, to prevent inconsistent results.
</p>
<p><b>[e52bf612] 2022-03-17-10-05</b>: there is a tradeoff between decreasing lock overhead and decreasing lock contention when choosing the number of locks in synchronization.
</p>
<p><b>[777a1fba] 2022-03-17-10-04</b>: lock contention: occurs when one process or thread attempts to acquire a lock held by another process or thread.
</p>
<p><b>[dc0ac8d7] 2022-03-17-10-03</b>: lock overhead: the extra resources for using locks, like the memory space allocated for locks, the CPU time to initialize and destroy locks, and the time required for releasing locks.
</p>
<p><b>[80fbebf2] 2022-03-17-10-01</b>: lock granularity: The granularity is a measure of the amount of data the lock is protecting.
</p>
<p><b>[3162a47c] 2022-03-17-09-59</b>: spinlocks are efficient if threads are likely to be blocked for only short periods, but start to become wasteful if held for longer durations.
</p>
<p><b>[afdafef6] 2022-03-17-09-58</b>: spinlock: a lock that causes a thread trying to acquire it to simply wait in a loop ("spin") while repeatedly checking whether the lock is available.
</p>
<p><b>[350727ef] 2022-03-17-09-57</b>: a careless use of locks can result in a deadlock.
</p>
<p><b>[88c97036] 2022-03-17-09-57</b>: deadlock: a situation in concurrent computing where no member of some group entities can proceed because each waits for another member, including itself, to take action (usually releasing a lock, or sending a message).
</p>
<p><b>[f2ba7cc4] 2022-03-17-09-55</b>: If atomic locking operations are available, one can use either Dekker's algorithm or Peterson's algorithm.
</p>
<p><b>[a4ca8bb6] 2022-03-17-09-53</b>: fetch-and-add (FAA): an atomic instruction that increments a value at address x by a, and then returns the original value at x.
</p>
<p><b>[c01b9b1c] 2022-03-17-09-51</b>: atomic operations in the context of multithreading can be said to be "uninterruptable", and serve as the basis for many primitives used in multithreaded programming such as mutexes and semaphores.
</p>
<p><b>[f87c5a50] 2022-03-17-09-48</b>: atomicity: an instruction that is an indivisible and irreducable series of database operations such that either all occurs or none occurs.
</p>
<p><b>[b09e7966] 2022-03-17-09-46</b>: test-and-set: instruction used to write (set) 1 to a memory location, and return its old value as a single atomic operation.
</p>
<p><b>[10a99087] 2022-03-17-09-44</b>: the atomicity of CAS guarantees that the new value is calculated based on up-to-date information.
</p>
<p><b>[2b86a04b] 2022-03-17-09-43</b>: compare and swap (CAS): an atomic instruction used in multithreading to achieve synchronization. It compares the contents of a memory value with a given value, and if they are the same, modifies the contents of the memory location with a new given value.
</p>
<p><b>[6974b4ce] 2022-03-17-09-40</b>: the simplest type of lock (mutex) is a binary semaphore.
</p>
<p><b>[9dc9f824] 2022-03-17-09-40</b>: critical section: a shared resource in concurrent programming that needs to be protected in ways that avoid concurrent access.
</p>
<p><b>[6afb2071] 2022-03-17-09-37</b>: semaphore: a variable or abstract data type used to control access to a common resource by multiple threads and avoid critical section problems in a concurrent system.
</p>
<p><b>[52e1453a] 2022-03-17-09-34</b>: mutex: short for mutual exclusion. A synchronization primitive that enforces limits on access to a resource when there are many threads of execution.
</p>
</div>
</body>
</html>
