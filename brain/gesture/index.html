<!DOCTYPE html>
<html lang="en">
<head>

<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<link rel="stylesheet" href="/brain/css/style.css">

</head>
<body>
<div id="main">
<title>Gesture</title>
<h1>Gesture</h1>
<p>Messages tagged with the label <code>gesture</code>.
</p>
<p><b>[2ed6a8c8] 2022-11-26-06-29</b>: Gesture Paths: a construct that can be used to represent Gesture. 
</p>
<p><b>[a283189f] 2022-11-26-06-29</b>: The goal of the Gesture Path is to have a high level construct that can be converted to Uxn code in GestVM. 
</p>
<p><b>[37175300] 2022-11-26-06-29</b>: A Gesture Path is a "Path" in the CS sense. Start value, end value, and a sequence of scalars connected together by things called trajectories. A, B, C. 
</p>
<p><b>[8fd7c0cd] 2022-11-26-06-29</b>: Trajectories are kind of like duration, but they are more accurately speeds in the context of GestVM (specifically, rate multipliers for the input conductor). 
</p>
<p><b>[4b80474f] 2022-11-26-06-29</b>: A Gesture Path is very similar to how a breakpoint line generator would be described. 
</p>
<p><b>[bdf81b8e] 2022-11-26-06-29</b>: Special START and END markers that exist outside of the path: START can be the end of a previous path or empty; END path can be the start of the next path or empty. 
</p>
<p><b>[ab26ab55] 2022-11-26-06-29</b>: An empty START value inidicates the beginning of the gesture, which means the gesture needs to be initialized to the value at the start of the path. An empty END value means the end of Gesture, so hold onto the last value of the path. 
</p>
<p><b>[ec2ca7d2] 2022-11-26-06-29</b>: Non-linear gesture path: path that has a branch point. Which branch it chooses it determined by some kind of external state (user input, random number generator). 
</p>
<p><b>[619be10f] 2022-11-26-06-29</b>: Thinking about anthrosound: external states could be like pheromones. Sound object critters could "smell" the state and instinctively know where to go. 
</p>
<p><b>[c4a96b2d] 2022-11-26-06-29</b>: Non linear paths could be built up of smaller linear paths. 
</p>
<p><b>[40c2e7fe] 2022-11-26-06-29</b>: They will hopefully turn out to be a useful construct for building up complex Gesture systems. 
</p>
<p><b>[65272cbc] 2022-11-25-15-31</b>: Current headspace: building a notation system for Gesture. A way of representing what are essentially breakpoint lines in a pretty way. 
</p>
<p><b>[2bcb4e9f] 2022-11-25-15-31</b>: These are not sounds, these are lines that could ideally control sounds. They are related. 
</p>
<p><b>[90d8188c] 2022-11-25-15-31</b>: There is a difference between notating for gesture and notating for sound. Ideally, the notation system should be for gestures that lead to beautiful sound. But that isn't always the case. 
</p>
<p><b>[2cd6b50f] 2022-11-25-15-31</b>: Look at written language: this a much closer symbolic represntation of sound, since they usually have a correspondence to phonemes. So, symbols for phonemes. 
</p>
<p><b>[59fc140e] 2022-11-25-15-31</b>: With Gesture, one can get quite stuck thinking about just the lines, but it does need to get to sound eventually. The grand plan is to use Gesture to build sound objects with personality and character. Having musical counterpoint be the result of these objects socializing with one another. 
</p>
<p><b>[dd53921a] 2022-11-25-15-31</b>: It's possible more notation will be needed for the gestlings series, as lines may be too low level. 
</p>
<p><b>[1c4cd9f6] 2022-11-24-07-06</b>: Gesture is a system that produces sound structures, inspired by the human voice and lyricism. Perhaps someday, it will push beyond the voice and lyricism and produce novel structures on its own terms. 
</p>
<p><b>[2fa2c58a] 2022-11-20-10-27</b>: not a lot of active work done here in a while. All my attention has been placed into a new project called (<a href="#">gestlings</a>), which aim to be studies in Sonic Gesture.
</p>
<p><b>[68c0fc1c] 2022-07-18-13-13</b>: Where this is all headed: construction of a notation system for synthesized gesture. 
</p>
<p><b>[e2e3a9ce] 2022-07-18-12-58</b>: Some motions imply a kind of "swooshing" motion with the entire hand. It's a physical gesture inputting in a synthesized gesture! 
</p>
<p><b>[8bd27e91] 2022-07-18-10-52</b>: Keyboards and mouse driven systems will ultimately yield the same kinds of ideas. Let's make new systems and amuse ourselves. 
</p>
<p><b>[bc7fd4b2] 2022-07-18-10-52</b>: Smaller latency creates a tighter creative feedback loop, which hopefully should create a better flow state. 
</p>
<p><b>[9fcf3086] 2022-07-18-10-52</b>: We are limited to our limbs for notating gesture. 
</p>
<p><b>[9f8ca7e6] 2022-07-18-10-52</b>: In a way, ergonomics influences the possible notation systems that can be used. 
</p>
<p><b>[5af50be3] 2022-07-18-10-52</b>: The way we carry our body and perform actions with our limbs carries certain meaning. It influences how we think. 
</p>
<p><b>[b2288656] 2022-07-18-10-52</b>: Weird input systems yield unusual actions with our limbs yield new creative perspectives and headspaces. 
</p>
<p><b>[23931930] 2022-07-18-10-52</b>: Ergonomics is about efficiently moving the body to do a particular task. In this case, the task would be producing or notating gesture. 
</p>
<p><b>[4f132990] 2022-07-18-10-52</b>: Rework classic definition of Gesture: <b>efficient</b> movement of the limbs to <b>notate</b> a gesture, to be synthesized and performed later. 
</p>
<p><b>[7dca32d4] 2022-07-18-10-52</b>: Gesture notation system should be: efficient, natural, fast. This produces a smooth creative feedback loop. 
</p>
<p><b>[89b59e25] 2022-07-18-10-52</b>: Movement of the limbs: these are typically our hands and fingers working a peripheral (keyboard, mouse, controller, etc) connected to a computer. System interprets these actions and in turn performs a gesture. Assuming a realtime system. 
</p>
<p><b>[f4202093] 2022-07-18-10-52</b>: The amount of time between the movement of the limbs and the synthesized gesture performed by the computer is the latency of the creative feedback loop. 
</p>
<p><b>[96abc39f] 2022-07-17-14-17</b>: Synthesized gesture: a technical foundation for things like lyricism, singing, asemic speech, speeched music. 
</p>
<p><b>[5c973180] 2022-07-17-14-17</b>: A line of thinking between synthesized gestured and cute singing cartoon characters. 
</p>
<p><b>[09e032cc] 2022-07-16-15-16</b>: Concern: what if the natural affordances of the Grid are too different from Gesture? Simply the wrong tool for the job. 
</p>
<p><b>[34bd5d68] 2022-07-16-10-58</b>: Input addresses how to physically write gestures for a computer to interpret. Physiologically: how can I get my limbs moving in a way that my computer will understand? Press, turn, etc. Can I do it in an ergonomic, comfortable, intuitive way? 
</p>
<p><b>[1f0ef6bb] 2022-07-16-10-58</b>: Display: once a gesture is represented inside of a computer, how can it be displayed in a human readable way? 
</p>
<p><b>[7b4e222a] 2022-07-16-10-58</b>: Gesture Signal Generators are line generators. The conventional way to show lines is with plots. Plots have diminishing returns for readability after a certain size, and when there are multiple different lines happening at once. 
</p>
<p><b>[34ba568b] 2022-07-16-10-58</b>: Performance: how does the computer take in structured gesture and perform it? These gesture systems and algorithms are in place, and is currently the most clear. 
</p>
<p><b>[eca494ab] 2022-07-16-10-58</b>: Considerations for Gesture: Input, Display, Performance. 
</p>
<p><b>[ba7283a5] 2022-07-16-10-58</b>: This may be similar to MVC? 
</p>
<p><b>[f9b3493d] 2022-07-16-10-58</b>: It's not enough to develop algorithms for Gesture. One also has to construct gestures, and this is done using some kind of input mechanism. 
</p>
<p><b>[20a6945e] 2022-07-16-10-58</b>: How I'm currently inputting gesture: my keyboard and a text editor. How I'd like to do it: using things like my Grid and Arc. 
</p>
<p><b>[f8f803f1] 2022-07-10-18-52</b>: Birdsong is very gesture oriented. Very hard to notate using traditional western notation. 
</p>
<p><b>[02721c78] 2022-07-09-15-24</b>: Another way of framing gesture: Nonverbal action with ones body to express some abstract idea. In a way, this is what musicians do when they are playing their instruments. 
</p>
<p><b>[bfbd7720] 2022-07-09-15-24</b>: Physical Gesture Being Applied to Physical Sound: Musicians using gestures produced from their body to manipulate some kind of acoustic musical instrument. 
</p>
<p><b>[31998449] 2022-07-09-15-24</b>: When I play my upright bass, my hands work closely with the laws of physics in the universe to get it to produce a meaningful sound. We are at the whims of Mother Nature. 
</p>
<p><b>[f4f42055] 2022-07-09-15-24</b>: When instruments are electronic instead of acoustic, the performers are less physically constrained by the laws of physics to produce a meaningful sound (there's still the physics of electricity, which will be overlooked for now). This is synthesized sound. 
</p>
<p><b>[cea59827] 2022-07-09-15-24</b>: Physical Gesture Being Applied to Synthesized Sound: musicians using gestures produced from their body to manipulate an interface for an electronic instrument (such as the Theremin). 
</p>
<p><b>[ff9c3873] 2022-07-09-15-24</b>: Despite it's limited dimensionality, the Theremin is a very nuanced instrument, whose interface capable of very expressive music. Ability to capture physical gesture quite accurately. Leverages our fine motor skills. 
</p>
<p><b>[a151e2fd] 2022-07-09-15-24</b>: Synthesized Gesture Applied To Synthesized Sound: Write computer programs that produce sound, as well as programs that produce gestures that control that sound. Aim is to imitate the continuous gestures produced by a physical human (in a very simplified way). 
</p>
<p><b>[9425d3ba] 2022-07-09-15-24</b>: With synthesized gesture, there is still a human interacting with the comptuer to make things go. Let's assume they are still musicians. What are they doing with their limbs instead of using them to directly manipulate a musical instrument? 
</p>
<p><b>[c5d8194b] 2022-07-09-15-24</b>: Cannonical definition of Gesture -> physical gesture, physical sound -> physical gesture, synthesized sound -> synthesized gesture, synthesized sound. 
</p>
<p><b>[d6e34c5e] 2022-07-09-15-24</b>: Cannonical Gesture: movement of the limbs or action to convey some sort of meaning. 
</p>
<p><b>[99190556] 2022-07-07-16-01</b>: Before "Gesture" was a term in my computer music vocabulary, I was exploring gesture-aligned concepts in my software. Things like libline (2015-2016) was motivated by the desire for better control signal generators in Sporth. 
</p>
<p><b>[6ac3cd98] 2022-07-07-16-01</b>: Gesture has been an incremental idea over several years. 
</p>
<p><b>[622cb7d0] 2022-07-07-16-01</b>: I was writing about a "Gesture Sequencer" a year before I even wrote any code for it. I don't even think I was thinking about things like phasors and rephasors controlling it at the time either. 
</p>
<p><b>[b612ca61] 2022-07-07-16-01</b>: Before the Gesture Sequencer was an idea, circa 2019, I was at a choral concert, thinking about how the voices interacted in the acoustic space. Which to me is the guiding principal behind what I think of as Gesture in music. 
</p>
<p><b>[6b1bba61] 2022-07-07-16-01</b>: The term "Gesture" I stole from ICLC conference circa 2016 or 2017. In that context, they were using it in the context of thinking about live coding and gesture. 
</p>
<p><b>[b2b6a0fc] 2022-07-03-15-37</b>: Gesture Beyond Approximating Physical Gesture. 
</p>
<p><b>[51e6a75c] 2022-07-03-15-37</b>: What we are establishing: synthesized gesture being applied to synthesized sound. AKA fancy control signal generators controlling sound objects. 
</p>
<p><b>[a7183216] 2022-07-03-15-37</b>: Techniques for synthesized gesture are a kind of structured DSP. Approximating physical gesture and human performances are a starting point. Structures and algorithms can be explored on their own terms. 
</p>
<p><b>[ad1d16ad] 2022-07-03-15-37</b>: Coordinated Gestures: structures used to deal with coordinating and synchronizing many gestures at once. 
</p>
<p><b>[0a9f28fb] 2022-07-03-15-37</b>: N-order Gestures: Gestures controlling other gestures. 
</p>
<p><b>[e67d7eb6] 2022-07-03-15-37</b>: Gestures and Conductor Signals: A kind of N-order signal. When a gesture is programmed to be a conductor signal for another gesture. This can enable composition using conductors with asymmetric ramps. Technically this should work. 
</p>
<p><b>[5a7036bf] 2022-07-03-15-37</b>: Gestures and Interactivity: how to make Gestures controllable in realtime? 
</p>
<p><b>[ce27de87] 2022-06-30-14-25</b>: brain dump: (<a href="/brain/thoughts_on_gestured_sound">thoughts_on_gestured_sound</a>)
</p>
<p><b>[6324252c] 2022-06-30-14-14</b>: Musical Notes are more than just numerical sequences. 
</p>
<p><b>[7672df8e] 2022-06-30-14-14</b>: Gestures makes lyrical performance more of a possibility. 
</p>
<p><b>[6de2948c] 2022-06-30-14-14</b>: Realism not a goal: more about transferring headspace when I play music on my bass to work with a computer. 
</p>
<p><b>[47c73cde] 2022-06-30-14-14</b>: Anthropomorphic: sounds with personality. gesture could be a way of doing that. That's where I'm headed. Sounds that almost feel like creatures. 
</p>
<p><b>[29bec400] 2022-06-30-14-14</b>: Why a VM? Generative Music Structures. Wanted a way to build gestures with shared information and communication. GestVM is re-entrant. Concurrent gestures. 
</p>
<p><b>[347851c5] 2022-06-30-14-14</b>: Realizations from Gesture implementation: blurred line between notes (as seen in music theory) and signal. Leads to some interesting outcomes. Blending of Signal Theory and Music Theory. 
</p>
<p><b>[87bc1b5a] 2022-06-30-14-14</b>: Gesture Signal Generator: Input Signal of conductor, output is gesture. What if you fed back into conductor? State of sequence can influence the tempo of the conductor, causing the global tempo change. 
</p>
<p><b>[7d18b6c4] 2022-06-30-14-14</b>: Tempo automation: traditionally there's a global tempo track. Drop notes in, and things slow down depending on where they are. In new setup, the notes themselves are given weight. Weight "bends" the main tempo. Allows one to sequence passages that slow down and speed up automatically. Many notes with different weights can be played at once and things will sort themselves out. Good for isorhythmic composition techniques. 
</p>
<p><b>[13c11402] 2022-06-30-14-14</b>: Temporal Skewing: another way of warping time. two rephasors working together. One rephasor creates a single ramp, that is proptional to N ramps. A "monoramp". Monoramp is then put through a skewing function that adds exponential curve. Put that through another rephasor, that undoes the slowing operation of the previous rephasor. The rephasor logic doesn't care about slope of ramp. It only needs to be positive. Result of all this: time warping that is localized and relative to the bounds of the slower ramp. Not time will be destroyed or created. 
</p>
<p><b>[087c0bd6] 2022-06-30-14-14</b>: Articulated Gesture Signal Generator: Gesture plus an envelope generator. It's a way to add articulation. Percussive, transients, etc. Made up of 3 gesture signal generators (gate, signal a, signal b), and shaping parameters for the envelope (attack/release) that can also be GSGs. 
</p>
<p><b>[b4021974] 2022-06-30-14-14</b>: Solution: you need a centralized clock source. How to make this work for a line generator though? Phasors! Continuous signals that can embed timing information. You can now at every sample where you are in a period. Very easy to detect when a new period begins. 
</p>
<p><b>[b03b331d] 2022-06-30-14-14</b>: It is pretty trivial to "resynthesize" a new phasor based on the input of another phasor. Wait a sample, get delta, optional scale. Scaling value makes phasors at speeds relative to input phasor, like a clock subdivider. 
</p>
<p><b>[a2afec85] 2022-06-30-14-14</b>: Could use phasor as interpolation coefficient for interpolation in line generator. 
</p>
<p><b>[32f78481] 2022-06-30-14-14</b>: Problem: rephasor still has drift. 
</p>
<p><b>[6239a714] 2022-06-30-14-14</b>: First attempt to fix rephasor drift: Group things into phrases and then reset the clock at the end. Phrases would be specified in whole integer beats. Structured things in hierarchical "ramp tree". 
</p>
<p><b>[3523ee48] 2022-06-30-14-14</b>: Second attempt: correction is built in as a feedback loop. Look at where it is vs where it is supposed to be. Method requires two samples of delay, but it's a much more generalized rephasor now. No more more phrases, which were clunky. Lots more flexibility for control. 
</p>
<p><b>[1ddcf6a4] 2022-06-30-14-14</b>: Rephasor with automatic correction accidentally re-invented phase-locked loop. 
</p>
<p><b>[2dbd2f07] 2022-06-30-14-14</b>: Gesture Sequencing: the means of programming a Gesture Signal Generator. 
</p>
<p><b>[93518f44] 2022-06-30-14-14</b>: GestVM: use virtual machine to do sequencing. 
</p>
<p><b>[5b064f74] 2022-06-30-14-14</b>: Gestalts: perceptual movements and audio cues. These work together to create events our brain will lump together as a note. 
</p>
<p><b>[013eed56] 2022-06-30-14-14</b>: How to implement Gestures to produce Gestalts? Breakpoint line generators and automation curves work well! We have 'em already. But... how to use them outside of DAW? 
</p>
<p><b>[729110b0] 2022-06-30-14-14</b>: First attempt: libline. problem: drift. Roundoff and truncation created loss of precision which causes drift. Lines are in completely different place. 
</p>
<p><b>[0cefd13e] 2022-06-30-14-14</b>: Prop: similar problem. Marched to beat of it's own drum (clock source). Eventually drifted out of sync with other elements around it. 
</p>
<p><b>[1465c8d6] 2022-06-30-14-14</b>: Gesture in a computer music context is a set of synchronized coordinated control signals that modulate a sound object. 
</p>
<p><b>[1faf8d41] 2022-06-30-14-14</b>: Notes don't really exist when there isn't a human performer. Notes are notes. They are a shorthand interpretted by humans, and turned into physical that manifest into perceptual events of notes. These notes, now sound waves propagating through the air, are a little bit different than the notes on the page. We can call the semantic differences "interpretation". 
</p>
<p><b>[c8adf727] 2022-06-30-14-14</b>: Performance layer: representation of notes is different than how they are performed. This already happens in electronic music, but here it is more formally considered. 
</p>
<p><b>[c6085f7a] 2022-06-30-14-14</b>: Transcribing A Solo: different ways to write it down, depending on how you hearing it. Can be equally valid. 
</p>
<p><b>[2a37b245] 2022-06-30-14-14</b>: Define mathematical structures that crudely imitate the lyricism that human performers do naturally. 
</p>
<p><b>[56d70380] 2022-06-30-14-14</b>: Composing with control signals and curves: this is thinking with Gesture. 
</p>
<p><b>[acb5c69f] 2022-06-30-14-14</b>: Gesture addresses the question: what are interesting ways to structure music in a computer? 
</p>
<p><b>[c989190f] 2022-06-30-14-14</b>: Structures such as MIDI model music as a series of discrete events. The stuff underneath those events are hardly considered. 
</p>
<p><b>[b56817f3] 2022-06-30-14-14</b>: Gesture begins to address the stuff underneath the "notes": the Performance Layer. 
</p>
<p><b>[c54a0186] 2022-06-30-14-14</b>: Notes, though displayed as discrete units, will continuously flow from one to the other in performance. For some instruments this is very clear, like string instruments and singing. 
</p>
<p><b>[dd656f2b] 2022-06-30-14-14</b>: Consideration of monophonic instruments on their own terms. Lyricism. Computer generated lyrical performance. 
</p>
<p><b>[42a21753] 2022-06-30-14-14</b>: Theremin is a very high resolution controller. Sensitive to any movement. Exploited by Clara. Basically just controlling the frequency of humble oscillator. Not a Stradivarius. But the interface is compelling. Allows her to use natural dexterity and physical musicality. 
</p>
<p><b>[08907b26] 2022-06-30-14-14</b>: Inspiring notion: A compelling performance from well controlled frequency control. You don't need to invent complex sounds, just create really meaningful control mechanisms Overall, simplifies things. 
</p>
<p><b>[bdf37a6a] 2022-06-30-14-14</b>: What if the computer could be the performer? Thus... Synthesized Gesture performing Synthesized sound. 
</p>
<p><b>[e4ac92a2] 2022-06-30-14-14</b>: To some meaningful degree, capture the nuance of what is performed as some kind of procedurally generated continuous signal. Map it to something such as the frequency of oscillator. 
</p>
<p><b>[aa2f7c11] 2022-06-30-14-14</b>: Gesture, in this context, is a specialized control signal generator. 
</p>
<p><b>[49a4130b] 2022-06-30-14-14</b>: Gesture is an overloaded term. means a lot of things to a lot of different people. I mean something very specifically. 
</p>
<p><b>[3d7dd647] 2022-06-30-14-14</b>: Imagine a performed musical idea as a set of gestures that shape a particular sound. 
</p>
<p><b>[d1ba87d8] 2022-06-30-14-14</b>: "traditional" musician performing some kind of instrument: they move their limbs muscles to intentionally produce the kind of sound they have in mind. Physical gesture. physical sound. 
</p>
<p><b>[8068a810] 2022-06-30-14-14</b>: Next phase: electronic instruments that be human performed. physical gesture performing synthesized sound. Roughly the same level of dexterity. Not using of laws of physical acoustics to make sound, so things can be more ergonomic. More potential of sounds. It's a little more abstract. 
</p>
<p><b>[257e212b] 2022-06-30-14-14</b>: Synthesized sound is way simpler in sonic complexity compared to acoustically produced sound. 
</p>
<p><b>[f8d290cf] 2022-06-30-14-14</b>: Do we need to build more complex sounds to make better music? No! Consider Clara Rockmore and the Theremin. The Swan. It's a masterful virtuosic performance. It's mostly just frequency control. Amplitude is more slow-moving expression. 
</p>
<p><b>[cc36c05e] 2022-06-30-14-14</b>: Three sections: Development of idea. Implementation of idea. Extensions of the implementation. 
</p>
<p><b>[9f9f11b1] 2022-06-30-14-14</b>: Gesture refers to one or more control signals modulating the parameters of a sound object. 
</p>
<p><b>[263abb68] 2022-06-30-14-14</b>: Lines shaping the sound of a sound object over time. 
</p>
<p><b>[d4b9c03d] 2022-06-30-14-14</b>: simple mechanism is the basis for gesture. 
</p>
<p><b>[6050e432] 2022-06-30-14-14</b>: Realizations: when gesture is thought of as a signal or topology of signal flow, fun things happen. Events that feed back into conductor and influence it (temporal weight). Phasor (rephasor) combined together to skew it and that creates localized temporal skewing. Combinations of GSGs; mix/match. Articulated signal generator: envelope generator with GSGs for mare articulations to happen in signals. 
</p>
<p><b>[d886441d] 2022-06-30-14-14</b>: Don't need a GSG to make a gesture. Sample and hold can be used with phasor to make gesture. 
</p>
<p><b>[e7e35083] 2022-06-03-20-32</b>: "Diagrams, gestures and formulae in music" by G. Mazolla and M. Andreatta. This was mentioned to me while I was rambling about Gesture Mastodon. I don't understand the math, or really what this paper is about, but it looks intetesting. <a href="https://isidore.science/document/10670/1.rmwpgg">https://isidore.science/document/10670/1.rmwpgg</a> 
</p>
</div>
</body>
</html>
