<!DOCTYPE html>
<html lang="en">
<head>

<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<link rel="stylesheet" href="/brain/css/style.css">

</head>
<body>
<div id="main">
<title>The Art Of Computer Programming</title>
<h1>The Art Of Computer Programming</h1>
<p>Notes for The Art of Computer Programming series
by Donald E. Knuth.
</p>

<h2>Table Of Contents</h2>

<p><a href="/brain/TAOCP#2.2.2">2.2.2 Sequential Allocation</a></p>
<p><a href="/brain/TAOCP#2.2.3">2.2.3 Linked Allocation</a></p>
<p><a href="/brain/TAOCP#2.2.4">2.2.4 Circular Lists</a></p>
<p><a href="/brain/TAOCP#2.2.5">2.2.5 Doubly Linked Lists</a></p>
<p><a href="/brain/TAOCP#2.2.6">2.2.6 Arrays And Orthogonal Lists</a></p>
<p><a href="/brain/TAOCP#2.3">2.3 Trees</a></p>
<p><a href="/brain/TAOCP#2.3.1">2.3.1 Traversing Binary Trees</a></p>
<p><a href="/brain/TAOCP#2.3.2">2.3.2 Binary Tree Representation of Trees</a></p>
<p><a href="/brain/TAOCP#2.3.3">2.3.3 Other Representations of Trees</a></p>
<p><a href="/brain/TAOCP#2.3.4">2.3.4 Basic Mathematical Properties of Trees</a></p>

<h2>Chapter 1: Basic Concepts</h2>


<h3>1.1 Algorithms</h3>


<h3>1.2 Mathematical Preliminaries</h3>


<h3>1.3 MIX</h3>

<p>See: <a href="/brain/MIX">MIX</a> and <a href="/brain/MIXAL">MIXAL</a>.
</p>

<h3>1.4 Some fundamental programming routines</h3>


<h2>Chapter 2: Information Structures</h2>


<h3>2.2 Linear Lists</h3>


<h4>2.2.2 Sequential Allocation</h4>

<p><a id="2.2.2"></a>Data usually has much more structural data than we actually want to represent directly in a computer.  [gpuolfjer]
</p>
<p>Consider not only the data structure, but the class of operations to be done on the data.  [gfawddqwk]
</p>
<p>Linear List: sequence of nodes whose essential structure properties involve only the relative positions between items as they appear in a line.  [gpddodpju]
</p>
<p>Linear List Operations: Access, Insert, Delete, Combine, Split, Copy (List), Get Number Of Nodes, Sort, Search.  [guwwkfilp]
</p>
<p>Linear List Types: Stack: insert/delete at end of list, Queue: Insertions made at one end, deletions made at the other end, Deque: insert/delete at both ends.  [gkwwskdla]
</p>
<p>A deque is more general than a stack or queue.  [gdhlrslwo]
</p>
<p>Stacks are particularly useful for the processing of languages with a nested structure.  [gadqiousq]
</p>
<p>What is a Schachtelsatze? (!TAOCP vol1, pg 241).  [gurrlfdfu]
</p>
<p>Stacks generally occur most frequently in connection with explicitly or implicitly recursive algorithms.  [gukeuflup]
</p>
<p>Kind of like how the book references chapters that haven't been published yet. Long term thinking indeed.  [gpadakoqp]
</p>
<p>Special terms for stacks: top of stack, bottom of stack.  [gqesljhpf]
</p>
<p>Knuth does not like push/pop terminology. "The brevity of words 'push' and 'pop' has its advantages, but these terms falsely imply a motion of the whole list within computer memory. Nothing is physically pushed down; items are added onto the top, as in hnaystacks or stacks of boxes".  [gfjdpalhd]
</p>
<p>Terminology for queues: front and rear.  [gidppesse]
</p>
<p>Terminology for deques: left and right.  [gdlfuuhsl]
</p>
<p>Descriptive words in English for stack/deque/queue algorithms: "up-down" for stacks, "waiting in line" for queues, and "left right" for deques.  [giihdlrko]
</p>
<p>Simplest and most natural way to keep a linear list inside a computer is to put the list items in consecutive locations, one node after the other.  [gfshpdwdq]
</p>
<p>LOC(x[j + 1]) = LOC(x[j]) + c. C is the number of words per node.  [gqkiqahdl]
</p>
<p>In general: LOC(X[j]) = L0 + Cj.  [glaahlsrd]
</p>
<p>Sequential allocation is quite convenient for dealing with a stack.  [gpaujjaid]
</p>
<p>T is stack pointer, place Y on top of stack: T <- T+1; X[T] = Y;  [gfpihkaii]
</p>
<p>Queues and Deques get a little bit tricker. Uses two pointers called F and R.  [ghorpjsaj]
</p>
<p>Rear Insert: R <- R+1; X[R] <- Y;  [gasfrlkad]
</p>
<p>Front Remove: F <- F + 1; Y <- X[F]; if F = R, then set F <- R <- 0.  [gpdkedeoh]
</p>
<p>If R stays ahead of F, this approach takes up a lot of space.  [gufwkfufj]
</p>
<p>Better approach: set M nodes aside, arranged implicitely in a circle: if R = M then R <- 1, else R <- R + 1; X[R] <- Y.  And: If F = M, then F <- 1, else F <- F + 1; Y <- X[F].  [gaoahuoai]
</p>
<p>Actions above assume nothing goes wrong, which is quite unrealistic! To fix this, add underflow and overflow.  [gjjfieeai]
</p>
<p>Work on exersize 1. Apparently discusses nontrival aspect of this simple queuing mechanism.  [godkaides]
</p>
<p>What to do when underflow/overflow occurs?  [gqqeokksw]
</p>
<p>Underflow might be meaningful: remove items until underflow occurs.  [gjafhqalh]
</p>
<p>One would hate to give up when only one overflow occurs with room remaining in other lists.  [grupqrljh]
</p>
<p>If a program uses two lists, they can grown towards eachother. One expands to the left, the other expands to the right.  [gdawwwhrk]
</p>
<p>There is no way to store three or more lists with variable size such that: A. overflow happens only when the size of all lists exceeds total space. B. Each list has fixed location for bottom element. In order to satisfy A, give up B.  [gfauerqeq]
</p>
<p>Allow bottom elements of list to change positions.  [gqhepfrfh]
</p>
<p>No absolute memory address for L0. Not a constant.  [guhjuorhk]
</p>
<p>Study and figure out and explain MIX code in figure 8, pg 246.  [gpelqkeaa]
</p>
<p>Important Special Case: Each variable sized list is a stack.  [gfllokifw]
</p>
<p>Insert: TOP[i] <- TOP[i] + 1; if TOP[i] > BASE[i + 1], then OVERFLOW, else set CONTENTS(TOP[i]) <- Y.  [gqeifqkaj]
</p>
<p>Delete: if TOP[i] = BASE[i], then UNDERFLOW, else set Y <- CONTENTS(TOP[i]), TOP[i] <- TOP[i] - 1.  [gpqfeelwq]
</p>
<p>Note that BASE[i + 1] is (i + 1)st stack.  [grrufquio]
</p>
<p>When OVERFLOW occurs, repack memory. Some ways to do this outlined, intended for linear lists allocated sequentially.  [gwrjfqfrr]
</p>
<p>1 of 3 possibilities can happen when handling OVERFLOW:  [gjauskpsl]
</p>
<p>A. find smallest k i <= N and TOP[k] < BASE[k + 1], if it exists. Then move up a notch: set CONTENTS(L + 1) <- CONTENTS(L) for TOP[k] >= L > BASE[i + 1].  [giqiilwjd]
</p>
<p>I need to better grok how these shifts work here.  [gfswskahl]
</p>
<p>B. No k can be found like in A, but a k is found: largest k for 1 <= k < i and TOP[k] < BASE[k + 1]. Move down: set CONTENTS(L - 1) <- CONTENTS(L) for BASE[k + 1] < L < TOP[i].  [grkdkeqhk]
</p>
<p>C. TOP[k] = BASE[k + 1] for all k != i. There is no room. Give up.  [gwuwluiqq]
</p>
<p>Choosing better initial conditions helps avoid overflows in certain situations. However, it can save at most a fixed number of overflows.  [grrpfuofo]
</p>
<p>Improved Method: make room for more than one entry each time memory is repacked.  [gapfuweko]
</p>
<p>J. Garwick: Suggests complete repackinmg of memory when overflow occurs.  [guhsuswds]
</p>
<p>Algorithm G: Reallocate Sequential Tables. (pg 248).  [ghhwiiiku]
</p>
<p>Algorithm G: reallocate sequential tables (pg 248). If total memory not exceeded, will be re-arranged to make operation CONTENTS(TOP[i]) <- Y possible.  [groueskur]
</p>
<p>Most interesting part of algorithm G is repacking process. It is nontrivial due to all the shifting up and down.  [ghrrkhfqr]
</p>
<p>Algorithm R: relocate sequential tables. (pg 249). Based on easily verified fact that the data to be moved downward can't overlap with any data that is to be moved upwards or that will stay put.  [goadujkwr]
</p>
<p>Mathematical analysis of dynamic storage allocation like what is being done above (algo G + R) is difficult.  [glpddswfi]
</p>
<p>Some theory that can be derived for tables that only grow by insertion. Deletion and subsequent insertion to cancel effect ignored.  [gkuapwdiu]
</p>
<p>Moral of the story: a very large number of moves to be made if reasonably large number of items put into table. This is the price of packing many sequential tables tightly.  [gsqlhafeo]
</p>
<p>When memory is only half loaded, it tiends to require minimal arrangement with algorithm G.  [ghqhjrowj]
</p>
<p>Almost full memory: Algorithm R takes a while. OVERFLOW much more likely.  [gjhqehiwf]
</p>
<p>If many variable sized tables are used in a program, don't expect to use up 100% of memory before storage is exceeded.  [geafqlpde]
</p>
</p>

<h4>2.2.3 Linked Allocation</h4>

<p><a id="2.2.3"></a>Instead of sequential list, use a more flexible scheme consisting of a node containing a link to next node in list.  [gfqhouwee]
</p>
<p>Linked memory takes up more space, due to the links.  [gjwlauhar]
</p>
<p>But there is also implicit gain: tables can overlap, sharing common parts.  [gdqdhphqk]
</p>
<p>In many cases, sequential memory is less efficient, will often leave lots of unused space.  [gaiodwapa]
</p>
<p>Easy to delete an item from linked list. Sequential allocation generally implies moving a large part of the list into different locations.  [gsulpooae]
</p>
<p>Easy to insert item into the midst of a list with linking scheme. non-trivial with sequential table.  [gpsokfrkw]
</p>
<p>References are much faster in sequential case. usefulness of linked list predicated on the fact that a large majority of applications want to walk through lists linearly, not randomly.  [gujkeqqii]
</p>
<p>Linked lists can be split/joined easily.  [ghiejwkis]
</p>
<p>Linked lists lend themselves better to more intricate structures than simple linear lists. Variable number of variable sized lists, any node can point to start of new list, nodes can be linked together in several orders corresponding to different lists, etc.  [gowpjqroe]
</p>
<p>Simple operations, such as proceding sequentially through list, are typically slightly faster with sequential lists.  [gdpqohdis]
</p>
<p>Linking technique frees one from the consecutive nature of comptuer memory.  [gkjdkpise]
</p>
<p>AVAIL list/stack: list of available space, used with some mechanism for finding empty spacve for new node.  [gwqdpqafa]
</p>
<p>Set address of x to new node: X<-AVAIL, AVAIL<-LINK(AVAIL). Shorthand notation for this is X<=AVAIL.  [glapfifup]
</p>
<p>Node deleted, no longer needed: LINK(x)<-AVAIL, AVAIL<-X. Shorthand is AVAIL<=X.  [gapjfqapd]
</p>
<p>Storage pool: the set of all nodes that can be allocated.  [gujrdjrld]
</p>
<p>"We terminate the progrma with regrets"  [gahppwilf]
</p>
<p>Things omitted from initial discussion of AVAIL: how to setup, test for overflow, managing sizxe of storage pool.  [geisoirew]
</p>
<p>Current implemetnation/discussion of pools assume nodes of equal sizxe, different siees discusess 2.6.  [gelfowepo]
</p>
<p>Simplest kind of linked list is a stack.  [ghduofpah]
</p>
<p>Insert Y to top of stack with pointer P: P <- AVAIL, INFO(P) <- Y, LINKE(P) <- T, T <- P  [gijqpjkpr]
</p>
<p>Pop Y off stack: If T<code>NUL, then UNDERFLOW, otherwise set P<-T, T<-LINK(P), Y<-INFO(P), AVAIL<</code>P. Note: "<=" operator here puts P back into pool of free nodes.  [gffeijhkw]
</p>
<p>Study MIX program 10 (pg 258)  [gsdlrrrpw]
</p>
<p>Insertion/deletion operations involve cyclic permutation of 3 links.  [gauqfsjqs]
</p>
<p>P is AVAIL value before insertion (and P not NULL): AVAIL has previous value LINK(P). LINK(P) has previous value T. T has previous value AVAIL. AVAIL->T->LINK(P)->AVAIL  [gppkddeel]
</p>
<p>Deletion P is T before, P not NULL, Y<-INFO(P): AVAIL->LINK(P)->T->AVAIL.  [gqdrudhqj]
</p>
<p>Cyclic aspect not really relevant, important point is that precisely 3 links are permuted in these operations.  [gwihfphwl]
</p>
<p>Linked allocation applies in a particularly convenient way to queues.  [gpajaeqou]
</p>
<p>Make sure to handle empty lists properly. This is a common programmer error. "specify all conditions carefully".  [giuhdwhep]
</p>
<p>Another error: forgetting to change some of the links when structure s being maniupoulated.  [gpuiuuaou]
</p>
<p>Policty for empty queue: F eq NULL, R eq LOC(F).  [gjqhdpwki]
</p>
<p>Queue deletion: If F eq NULL, UNDERFLOW else set P<-F, Y<-INFO(P), AVAIL<=P and if F eq NULL, then set R<-LOC(F)  [gqdiaijuu]
</p>
<p>R is changed when queue becomes empty, this is the boundary condition.  [grpkhsiid]
</p>
<p>Not the only way to represent queues in a linearly linked fashion. Other ways are discussed later (see ex. 30)  [gqokolwei]
</p>
<p>So far, discussions on performing operations on tables have been abstract, no programs in which techinques are used, no onto practical examples!  [goweijarh]
</p>
<p>Topological sorting: important process in network problems, PERT charts, even linguistics.  [ghrwfsjpj]
</p>
<p>Topological sort is potentially useful with problems involving <code>partial ordering</code>.  [goedljiro]
</p>
<p>Partial ordering of set S is relation between objects of S, denoted by symbol (Paul: curvy less than equal to? looks like <=)  [gsssjhifq]
</p>
<p>Satisfies following properties for S (will use <= to represent notation used in book): Transitivity: x<<code>y and y<</code>z, x<<code>z. Antisymmetry: x<</code>y and y<<code>x, x</code>y. Reflexivity: x<=x.  [giqwshpsr]
</p>
<p>x<=y reads as "x preceds or equals y".  [gfjiqpeld]
</p>
<p>y!<=z reads as "y does not precede z".  [glophdeqa]
</p>
<p>PERT networks "x must be done before y".  [gksqduolw]
</p>
<p>Antisymmetry propety means there are no closed loops or paths that close on themselves. Problem of topological sort: emed the partial order in a linear orer.  [ghdrdsiqe]
</p>
<p>linear sequence a1, a2, ... an, aj<=ak, j<k.  [gussprewh]
</p>
<p>Algorithm proves tha this operation is possible for every partial ordering.  [gljeoapdo]
</p>
<p>Topological sort example: glossary of technical terms. Find a way to arrange the words in the glossary so that no term is used before it is defined.  [grqsrjpaf]
</p>
<p>Topological sort process: take object that isn't proceded by any other object in the ordering. Place first in output and remove from set S. repeat until whole set has been sorted.  [giqflkrij]
</p>
<p>algo T: topological sort (pg 265): inputs a sequence of relations j<=k, indicating that object j precedes k in a certin partial orering. output is set of objects embedded in a linear order.  [glijuswfo]
</p>
<p>Try algo T by hand on input 18 (264-265)  [geaqldlok]
</p>
<p>Combo of linked list and sequential allocation.  [gqeopjkri]
</p>
<p>Sequential memory used for main table, because it makes references to random parts of tables in T3.  [goioquosk]
</p>
<p>linked memory: tables of "immediate successors" no particular order in input.  [godlerdwl]
</p>
<p>Analysis of algo T: simple using Kirchoff's law.  [gurjjlrja]
</p>
<p>Exeuction time has approximate form $c2 n$. $m$ is number of relations, $n$ is number of objects. and $c2$ are constants.  [geikppuaf]
</p>
<p>Topological sorting technique similar to T (but without the important features of queue links): published by A.B Kahn.  [gakupokkq]
</p>
<p>Even better topological sort algorithm in 7.4.1 (not printed yet?)  [gkruuhfhh]
</p>
</p>

<h4>2.2.4 Circular Lists</h4>

<p><a id="2.2.4"></a>Circularly linked list: links back to first item instead of NULL.  [gsddqdjwf]
</p>
<p>Makes it possible to access all of the list starting form any point.  [gjfifiaqo]
</p>
<p>Important primitive operations: A. insert Y at left, B. insert Y at right, C. set y to left node and delete.  [ghhjowlsl]
</p>
<p>A. Insert Y at left: P<=AVAIL, INFO(P)<-Y, LINK(P)<-PTR, LINK<-(PTR)<-P. PTR: link variable that points to rightmost node in list. LINK(PTR): points to leftmost node in list.  [gsdoisewq]
</p>
<p>B. Insert Y at right: insert Y at left, then PTR<-P.  [gfjlpuepa]
</p>
<p>C. Set Y to left node and elete: P<-LINK(PTR), Y<-INFO(P), LINK(PTR)<-LINK(P), AVAIL<=P.  [gojujlewf]
</p>
<p>Operations above do not consider empty list can be handled if empty list handled by making PTR NULL.  [gwdkeejde]
</p>
<p>Operations give actions of output-restricted deque. Therefore circular list can be used as stack of queue.  [gliqqhkri]
</p>
<p>Operations A+C stack. Operations B + C: queue.  [guwppqeef]
</p>
<p>Erase a list (put all items on AVAIL): IF PTR ne NULL, then AVAIL <-> LINK(PTR). "<->" denotes P<-AVAIL, AVAIL <- LINK(PTR), LINK(PTR)<-P.  [gwrdqjoos]
</p>
<p>Insert entire list L2 at the right of L1: if PTR2 ne NULL, then: (if PTR1 ne NULL, then LINK(PTR1)<->LINK(PTR2)) SET PTR1<-PTR2, PTR2<-NULL.  [gffhewhid]
</p>
<p>Assumes PTR1 and PTR2 point to disjoint circular lists L1 and L2.  [gpffqaphw]
</p>
<p>Splitting circular list in 2: with above, can correspond to concatentation/deconcation of strings.  [gesdkowpd]
</p>
<p>Circular list with one pointer to rear node is equivalent to linear list with two pointers to front/rear.  [girraiwlu]
</p>
<p>How to find end of list when there is circular symmetry? Iterate throgh list, stop when start found again. Or, add special recognizable node as stopping place: list head.  [guuoqwjpd]
</p>
<p>List head makes it possible (though not efficient) to get to any point in the list from any other point.  [gqpqreawa]
</p>
<p>Example use of circular lists: arithmetic on polynomials in variables x,y,z with integer coefficeints.  [gqalakajw]
</p>
<p>Linked alocation works well: polynomials can grow to unpredictable size. May want to represent many polynomials in memory at once.  [grkflhppw]
</p>
<p>Algorithm A: addition of polynomials (pg 276).  [gdowdafld]
</p>
<p>Noteworthy feature of algorithm A: manner in which variable Q1 folows Q around the list.  [gosjqqprr]
</p>
<p>Algorithm M: multiplication of polynomials (pg 277).  [gwjssukqf]
</p>
<p>Algorithm M analogous to Algorithm A.  [giklwfafk]
</p>
</p>

<h4>2.2.5 Doubly Linked Lists</h4>

<p><a id="2.2.5"></a>Adds two links to each node: points to either side of node.  [gupieoquw]
</p>
<p>Manipulations of linked lists almost always become easier with list head. creates complete symmetry between left and right (loops back).  [ghdaujkps]
</p>
<p>List head satisfies: RLINK(LLINK(x)) \= LLINK(RLINK(x)) \= x  [gwdkudroh]
</p>
<p>Doubly linke list takes up more memory than singly. But tradeoff is worth it for the efficient operations with 2-way links.  [gfeieoulh]
</p>
<p>Deletion: RLINK(LLINK(X))<-RLINK(X), LLINK(RLINK(X))<-LLINK(X),AVAIL <= X.  [gupwofrdo]
</p>
<p>Nodes in one-way linked lists cannot be deleted without knowing the previous node.  [gpjwilsor]
</p>
<p>Several algorithms require removing random nodes from middle of list. Doubly linked lists suitbale for this.  [gsjhsqfaw]
</p>
<p>Easy to insert an adjacent node to NODE(X): P<=AVAIL, LLINK(P) <-x, RLINK(P)<-RLINK(X),LLINK(RLINKE(X)<-P, RLINK(X)<-P.  [glkasdjdf]
</p>
<p>Discrete simulation: simluation of system in which all changes are in the stae of system are assumed to happen at discrete instants of time.  [goifokuor]
</p>
<p>Program outlined simulates elevator system in mathematics building at caltech.  [gruprdpij]
</p>
<p>Five floors, number 0-4.  [gsliislef]
</p>
<p>Each floor has 2 call buttons: UP and DOWN, corresponding variables CALLUP[j] and CALLDOWN[j]. 0<\<code>j<\</code>4.  [gupfeusde]
</p>
<p>CALLCAR[j] varaiables. buttons within elevator car, which direct it to destination floor. 1 means pressed, cleared to 0 when fulfilled.  [grhdlioew]
</p>
<p>Elevator has one of three states: GOINGUP, GOINGDOWN, and NEUTRAL.  [godelhhkq]
</p>
<p>Eleavtor system is simulated using 2 coroutines: one for passegners, other for elevator.  [gehhfuuuq]
</p>
<p>TIME: variable for curret value of simulated time lcock in units o tenths of seconds.  [gilpkordj]
</p>
<p>Other variables: FLOOR: eleavtor position. D1: 0, except when people getting in/out. D2: 0, if elevator idle on floor for 30+ seconds. D3: 0, except when doors open and nobody is getting in/out.  [glqfaoeaq]
</p>
<p>Coroutine U (users) [pg 283]: everyone who enters the system begins to perform the actions specified below, starting at step U1.  [gajohroow]
</p>
<p>Coroutine E (eelvator) [pg 284]: this coroutine reprsents actions fo elevator. Step E4 also handles when people get in and out.  [goqfhfujd]
</p>
<p>Subroutine D (decision subroutine) [pg 287]: This subroutine is performed at certain critical times, as specified in coroutines above, when a decision about the elevators next direction is to be made.  [gedppfadk]
</p>
<p>Elevator system described above is complex compared to other algorithms discussed in this book. Choice of real-life system better than any cooked-up "textbook example" would ever be.  [glklhlrlq]
</p>
<p>Passing of simulated time and handling of simultaneity can be programmed by having each entity represented by node with NEXTTIME and NEXTINST fields.  [grqflqhas]
</p>
<p>NEXTTIME: time for when next action for this enttity will take place.  [gkkaoipjw]
</p>
<p>NEXTINST: memory address where this entity is so start executing instructions (analogous to ordinary coroutine linkage).  [gosiifwpd]
</p>
<p>WAIT: doubly linked list. entities placed here to wait for time to pass.  [ghqfffaqr]
</p>
<p>WAIT: "agenda" sorted on nexttime field.  [gdpkddjir]
</p>
<p>Doubly linked lists also used for elevator and QUEUE.  [glwifhirl]
</p>
<p>Program itself is quite long, can be broken up into 6 parts.  [ghriiwofa]
</p>
<p>First part: define initial contents of tables: WAIT, QUEUE, and ELEVATOR.  [gpjfdadhh]
</p>
<p>Next part, basic subroutines and main control routines for the simulation process.  [gjdqdikwu]
</p>
<p>Routine CYCLE: heart of simulation control. which activity is to act next?  [gqhqiahih]
</p>
<p>Program for coroutine U comes next, followed by coroutine E.  [gaaelhdes]
</p>
<p>Decision subroutine not considered here (see excercises).  [goshroaqw]
</p>
<p>Quasiparallel processing: technique of using WAIT list or agenda to control sequencing of coroutines.  [gsdjpahij]
</p>
<p>Use special trace program ("profiler") to get good indication of overall efficiency.  [gqilshdws]
</p>
<p>"It is hoped that some read will learn as much about simulation from the example above as the author learned about elevators while the example was being prepared"  [geppeqppu]
</p>
</p>

<h4>2.2.6 Arrays and Orthogonal Lists</h4>

<p><a id="2.2.6"></a>Simplest generalization of a linear list is a 2d or higher dimenionsal array of information.  [geidieqfu]
</p>
<p>2d MxN aray: each node A[j,k] belongs to two linear lists "row j" list and "column k" list.  [gqkirledd]
</p>
<p>When (2d) array is stored in sequential memory locations, storage allocated so that: LOC(A[j,k])\=(a0) + (a1)j + (a2)k.  [gwpfhsusp]
</p>
<p>4d array with one words elements Q[I,J,K,L]. Allocate storage to be LOC[Q[I,J,K,L] \= a0 + (a1)I + (a2)J + (a3)K + (a4)L.  [gfdlawwpr]
</p>
<p>Commonly allocated by arranging elements in lexicographic order, AKA "row major order".  [goueppjso]
</p>
<p>General definition for memeory storage of k-demmensional array with C-word elements A[I1, I2,..., IK]. (Outlined in book).  [gpfdfqqik]
</p>
<p>Can be used to correspond to number in mixed radix number system for representing date and time TIME[W,D,H,M,S]. Array would have 2,419,200 nodes. A "pretty fancy application" would use this. Not very practical.  [ghaejhdui]
</p>
<p>The normal moethd for storing arrays are suitable when all elements are present: a complete rectangular structure.  [goodiqhia]
</p>
<p>Triangular matrix: stores entries A[j,k], 0\<\<code>k\<\</code>j\<\=n.  [gopkuuqlp]
</p>
<p>Previous allocation method does not work for storing triangular matrix sequentially. New form required.  [gaehfkfrs]
</p>
<p>Lexicographic order does work example triangular matrix. Simple equation falls from this.  [gwriwoifh]
</p>
<p>Better approach involves packing two triangular matrices of the same size together.  [goqioddlf]
</p>
<p>Tetrahedral array: generalization of triangular matrices to higher dimensions.  [gwduadslp]
</p>
<p>Linked memeory allocation can also be applied to higher dimensional arrays in a natural way. Works well for non-rectangular structure.  [gleewwuks]
</p>
<p>Example: list in which each node has 4 link entries: SEX, AGE, EYES, HAIR. Represents Person.  [gopfjuias]
</p>
<p>Insertion would be efficient, deletion would be slow, unless double linking used.  [gqudjquoh]
</p>
<p>Sparse matrices: example that uses linked allocation for orthogonal lists. They are matrices of a large order whose elements are mostly zero.  [gpwdoqpqr]
</p>
<p>Use circularly linked lists for row and column: ROW/COL indices, VAL value, UP/LEFT links to next nonzero entry upwards/leftwards.  [goeallefs]
</p>
<p>Pivot step operation: example of nontrivial algorithm using sparse matrice in this form. Operation important part of algorithms for solving linear equations, inverting matrices, solving linear problems via simplex method.  [gruhlfsek]
</p>
<p>Algorithm S: Given a matrix as represented in figure 14,  perform pivot operation. [pg 304].  [ghohdeerl]
</p>
</p>

<h3>2.3 Trees</h3>

<p><a id="2.3"></a>Trees: most important nonlinear structures that arise in computer algorithms.  [gosidiqju]
</p>
<p>"branching" relationship between nodes like what is found in the trees of nature.  [gfdqewqpr]
</p>
<p>Finite set T with one or more nodes.  [gqqpkjfjr]
</p>
<p>One node is specially designated, called the root of tree root(T).  [gpuafadfj]
</p>
<p>remaining nodes partitioned into m (greater than 0) disjoint sets T1,...,Tm. Also are trees. Subtrees of root.  [gkeekdsah]
</p>
<p>Recursion is innate characteristic of trees, hence the recursive definition.  [gwiaidkqu]
</p>
<p>Degree: number of subtress of a node.  [gareeppww]
</p>
<p>Terminal node: node with degree of 0. Sometimes called leaf.  [gaqrwepjj]
</p>
<p>Branch node: a non-terminal node.  [gdjhfsifr]
</p>
<p>Level: root(T) is 0, any other is one higher than nodes level with respect to subtree of root(T) containing it.  [guafqwpsi]
</p>
<p>Ordered tree: tree where relative order of the subtrees is important. Sometimes called "plane trees".  [gpjehpoew]
</p>
<p>Oriented tree: disregard ordering of subtrees of nodes, treat them as equivalent. Only relative oreintation considered, not order.  [gjqurjlqj]
</p>
<p>Forest: (usually ordered) set of zero or more disjoint trees.  [gkkfueedk]
</p>
<p>Tree vs forest: little distinction. Delete root of tree, and you have a forest. Add node to a forest and regard trees as subtrees of new node, yields a tree.  [greueplpp]
</p>
<p>Binary tree: finite set of nodes that is either empty or consists of a root and the elements of two disjoint binary trees called the left/right subtrees of the root.  [geqluqlwk]
</p>
<p>Ways to show tree structre: nested sets, nested parentheses, indentation.  [gufaejqoh]
</p>
<p>A forest can be regarded as special case of a list structure.  [guiakqhol]
</p>
<p>List: a finite sequence of zero or more atoms or lists.  [gijdfruju]
</p>
<p>Atom: undefined concept here, can refer to elements from any universe of objects that can be desired as long as it is distinguishable from list.  [grpfkewar]
</p>
<p>Lists vs trees: lists can overlap, or even be recursive.  [gehaqeiod]
</p>
</p>

<h4>2.3.1 Traversing Binary Trees</h4>

<p><a id="2.3.1"></a>Binary trees are good to understand before other trees, as general trees are usually represented in terms of some equivalent binary tree (2.3.2).  [glkjqirej]
</p>
<p>Traversing, or "walking through" tree. Visit nodes exactly once.  [gfqflpjif]
</p>
<p>Complete traversal is linear arrangement of nodes.  [gaeuhawes]
</p>
<p>3 principal ways to traverse binary tree: preorder, inorder, postorder.  [ghkerakkq]
</p>
<p>preorder: root, traverse left, traverse right. inorder: traverse left, root, traverse right. postorder: traverse left, traverse right, root.  [gdjqkqrqj]
</p>
<p>names come from relative position of root with resepct to its subtrees.  [gqsrljulf]
</p>
<p>in many applications of binary tree, symmetry between left/right subtrees.  [gfesqjrri]
</p>
<p>symmetric order: AKA inorder.  [gfipwahhq]
</p>
<p>Algorithm T: traverse binary tree inorder [pg 320].  [gqlashslp]
</p>
<p>"visit" here means do whatever activity intended as tree is being traversed.  [gfrarsowp]
</p>
<p>Proof that algo T works see pg 320.  [ghjrwojfu]
</p>
<p>preorder algo almost identical inorder. postorder slightly more difficult.  [gikrieejh]
</p>
<p>Notation for successors/predecessors of nodes. let <code>p</code> be pointer to binary node.  [grqraihhk]
</p>
<p><code>p*</code> is address of successor of NODE(P) in preorder. <code>p$</code> is successor, inorder. <code>p#</code> is successor, postorder. <code>*p</code> is predecessor, preorder. <code>$p</code> is predecessor, inorder. <code>#p</code> is predecessor, postorder.  [gphelahpf]
</p>
<p>ex. 16 can help clear up confusion about notation.  [gewuiweal]
</p>
<p>Threaded tree representation: terminal links (otherwise wasted and unused space) are replaced by "threads" as an aid to traversal.  [gjwoqhdwl]
</p>
<p>Threads always go to a higher node of tree.  [gqjfialka]
</p>
<p>Every node now has exactly 2 links.  [gwipqopwl]
</p>
<p>Use some sort of tag to distinguish between thread and regular link.  [grufhpsjj]
</p>
<p>Traversal becomes simpler with threaded tree.  [gallwujke]
</p>
<p>Algorithm S: symmetric (inorder) successor in threaded binary tree [pg 323].  [gjadhfeli]
</p>
<p>Compared algo S to algo T: no stack required.  [goowpsdia]
</p>
<p>Program T: Implementation of Algo T.  [gskqjqjui]
</p>
<p>Program S: Implementation of Algo S.  [guprhsusi]
</p>
<p>Threaded trees take a bit more time to insert/delete nodes.  [gkeqfqopj]
</p>
<p>Threaded trees grow almost as easily as ordinary ones do.  [glefrikio]
</p>
<p>Algorithm I: insertion into threaded binary tree [pg 327].  [gopuwflew]
</p>
<p>Right threaded binary tree: threaded RLINKS, LLINKS that are empty set to NULL. Middle ground between threaded and unthreaded representation.  [gfkphqudl]
</p>
<p>Two binary trees T and T' are said to be similar if they have the same structure. Informal: they have the same shape. Formal: both empty, or both non-empty and L/R subtrees are respectively similar.  [gpwqaeflp]
</p>
<p>T and T' are said to be equivalent if they are similar and corresponding nodes contain the same informaiton.  [gelwouehd]
</p>
<p>Figure of 4 binary trees helpful [pg 328]. illustrates dissimilar, similar, and equivalent.  [giiqpeolw]
</p>
<p>Theorem A: helpful for determining if trees are similar or equivalent. [pg 328]  [gsjlelarr]
</p>
<p>Algorithm C: copy a binary tree [pg 329].  [grlekkdjf]
</p>
</p>

<h4>2.3.2 Binary Tree Representation of Trees [pg 334]</h4>

<p><a id="2.3.2"></a>We now turn from binary trees to just plain trees.  [guiuwqqse]
</p>
<p>How to represent any forest as binary tree [see pg 334-335 for figures and visual explanation].  [gipqaejus]
</p>
<p>Natural correspondence between forest and binary tres. AKA the transformation from forest to binary tree.  [gqipseprj]
</p>
<p>Rigorous definition for how to binary tree is corresponding to the forest [pg 335].  [gpujahole]
</p>
<p>Threaded binary tree representation: right thread links go to rightmost child of a family to the parent.  [geeuqokqd]
</p>
<p>Left thread links do not have such a natural interpretation. Lack of symetry between left and right.  [gwashhpkd]
</p>
<p>Preorder and postorder traversal can be applied to forest (therefore, trees). Inorder doesn't have a simple analog from binary trees.  [geadhhowa]
</p>
<p>Let A: visit root of first tree. B: traverse subtrees of first tree. C traverse remaining trees. Preorder: ABC. Postorder: BAC.  [gwjeeposo]
</p>
<p>Preorder is "time-honored concept", sometimes can be meaningfully called "dynastic order".  [gurfrshju]
</p>
<p>Order of succesion to throne: lineal chart of all the aristocracy, write out nodes in preorder, consider only the living.  [gileespaq]
</p>
<p>Traversing forest in preorder exactly the same as taversing corresponding binary gree in preorder.  [ghwkkpeoq]
</p>
<p>Traversing forest in postorder is exactly the same as traversing the correspondin binary tree inorder.  [gifepeadj]
</p>
<p>Use trees to represent algebraic formulas.  [gqfjswhrl]
</p>
<p>Polish notation: Preorder traversal: prefix notation of formula. Postorder traversal: postfix notation.  [gkowisrso]
</p>
<p>Algorithm D: differentiation. [pg 340]  [glejhsokk]
</p>
<p>Some notes on differentiation [pg 338-339].  [gslweqlpe]
</p>
<p>Algo D is like the control routine for an interpretive system or machine simulator. To complete it, define routines that peform th actual differentiation.  [gfswkasji]
</p>
<p>Build tree construction function that makes new trees by joining smaller ones together.  [gwfqlqrol]
</p>
<p>TREE function: x is node, either constant, variable, or operator. U and V are pointers to trees.  [gewusoheo]
</p>
<p>TREE(x, U, V): makes new tree with x in its root node and U and V subtrees of root.  [gsfskfjoq]
</p>
<p>TREE(x, U): tree with only one subtree.  [gulwuaiio]
</p>
<p>TREE(x): new tree with x as terminal root node.  [gqhrupsoa]
</p>
<p>COPY(y): copies tree provided by U.  [ghkpwqela]
</p>
<p>Nullary operators (constants and variables), Unary operators (logarithm and negation), binary operators (addition, subtraction, multiplication, division, exponentiation).  [gqdkhajfo]
</p>
<p>Program D: differentiation. [pg 343].  [grploehpq]
</p>
</p>

<h4>2.3.3 Other Representations of Trees</h4>

<p><a id="2.3.3"></a>Sequentional memory techniques: represent trees in sequential memory.  [ghdodjwrs]
</p>
<p>Preorder sequential representatiln: all subtrees of a node appear immediately after that node, RLINK arrows never cross eachother, LTAG field is made redudnant.  [glfpiapdu]
</p>
<p>RLINK field almost redudndant, RTAG and LTAG are what is needed to represent structure.  [gukdkpalo]
</p>
<p>RLINK/LTAG redudancy is little to no help unless scanning forest sequentially. Otherwise, extra computation required to deduce missing information.  [glrojqadi]
</p>
<p>RLINK is null for more than half of sample forest. Ways to make use of wasted space:  [gpaquhjra]
</p>
<p>1. Fill RLINK with subtree below that node. RLINK now called SCOPE.  [giadudwuf]
</p>
<p>2. Decrease node size by removing RLINK field, add special "link" nodes just before nodes that formerly had non-null RLINK.  [gakdkelfl]
</p>
<p>3. OMIT RLINKS instead of LLINKS. List nodes in a new order called family order.  [gpaslifau]
</p>
<p>Family order for forest: visit root of first tree. Traverse remaining trees (family order). Traverse subtrees of root of first tree (family order).  [gqflkeuij]
</p>
<p>Level order: list nodes left to right, one level at a time. Similar to family order, but families are chosen FIFO instead of LIFO.  [grqaidsur]
</p>
<p>Postorder with degrees: list nodes in postorder and give the degree of each node instead of links.  [gswkukssr]
</p>
<p>Postorder with degrees useful for "bottom-up" evaluation of functions defined on nodes of a tree.  [giejhwaoo]
</p>
<p>Algorithm F: evaluate a localy defined funciton in a tree. [pg 352].  [gqhkjpjih]
</p>
<p>ex 2.3.2-10: proof that shows postorder with degrees has sufficient information for tree structure.  [gekfrdrfd]
</p>
<p>In binary tree representation LLINK can be more accurately called LCHILD.  [gwkqqwiea]
</p>
<p>Leftmost child usually the "youngest" of children in tree.  [grqkqeeuw]
</p>
<p>Triply linked tree: each node has LCHILD, RLINK, and PARENT links.  [gsderfefo]
</p>
<p>Upward links useful in an algorithm for dealing with equivalence relations.  [girdrkfeq]
</p>
<p>Equivalence relation: relation between the elements of a set of objects satisfying transitivity, symmetry, and reflexivity.  [gudwisokr]
</p>
<p>Quite different from partial ordering, even though 2 of 3 defining properties are the same.  [gsaiephqe]
</p>
<p>Equivalence problem: read in pairs of equivalent elements, determine later wheter 2 particular elements can be proved equivalent or not on the basis of given pairs.  [giudffhhd]
</p>
<p>Equivalence classes: disjoint classes such that 2 elements are equivalent if and only if they belong to the same class.  [glhwpiwew]
</p>
<p>Algorithm E: process equivalence relations. [pg 354].  [gjhaswlao]
</p>
<p>Try algorithm E on input 11 [pg 355]  [gsklaupfu]
</p>
<p>See exercise A. "remaining relations are more interesting".  [gkiapekiu]
</p>
<p>8 binary tree methods possible by using straight, circular, and doubly linked lists in the LLINK/RLINK directions.  [geuqrsreu]
</p>
<p>Ring structure: what happens when circular linking is used in both directions.  [gqoksaopf]
</p>
<p>Algorithm A: addition of polynomials [pg 357].  [gujaaakwf]
</p>
</p>

<h4>2.3.4 Basic Mathematical Properties of Trees</h4>

<p><a id="2.3.4"></a>Nonmathematicl readers are advised to skip to 2.3.4.5.  [gpdlkwuuu]
</p>
<p>Graph: set of points (vertices) together with a set of lines (edges) joining certain pairs of distinct vertices.  [gfirjpded]
</p>
<p>Vertices are adjacent if there is an edge joining them.  [goisahrih]
</p>
<p>Walk: sequence of adjacent vertices, with a start/end vertice.  [gpfofqewl]
</p>
<p>Walk is a path if vertices are distinct.  [gfjpleilu]
</p>
<p>Cycle: path with at least 3 vertices, first and last vertice the same.  [gdqfladkq]
</p>
<p>Graph is connected: path between any two vertices in graph.  [glffieslj]
</p>
<p>Free tree/unrooted tree: connected graph with no cycles.  [ghsqhoehf]
</p>
<p>Theorem A: if G is a graph, the following statements are true:  [glssdrlda]
</p>
<p>A. G is a free tree.  [giwwwjspk]
</p>
<p>b. G is connected, but if any edge is deleted, the resulting graph is no longer connected.  [gdwulfsrw]
</p>
<p>c. If V and V' are distinct vertices of G, there is exactly one simple path from V to V'.  [gaadjwfwl]
</p>
<p>If G is finite, contains a non-zero number of vertices, following is equivalen to a, b, and c:  [gllaaplhw]
</p>
<p>d. G contains no cycles and has n-1 edges.  [giqqerhaq]
</p>
<p>e. G is conneted and has n-1 edges.  [gidopuras]
</p>
<p>Proof is on pg. 364.  [grufwljwl]
</p>
<p>Applying Kirchhoff's law in the analysis of a free tree, using as an example an abstracted flow chart for program 1.3.3A.  [gpipopwkk]
</p>
<p>Goal: find all relations between the quantities that are implied by Kirchhoff's law, hopefully gain insight into problem.  [geswesisr]
</p>
<p>Convert flowchart to graph. Boxes become vertices. Arrows become edges.  [guqephalf]
</p>
<p>Thick line denotes a free subtree.  [gforofwek]
</p>
<p>G': free subtree of G. consequence of theorem A. Any edge V-V' not in G', plus G', contains exactly one cycle.  [gwkleoeff]
</p>
<p>Add single edge to flowchart free subtree G', obtain fundamental cycles.  [grkqlehdp]
</p>
<p>Each fundamental cycle represents a solution to Kirchhoff's equations.  [gkrioiuoo]
</p>
<p>Proof that all solutions of Kirchhoff's equations may be obtained as sums of multiples of the fundamental cycles. [pg 367].  [guukpwwrs]
</p>
<p>Any execution of a computer program that goes from start to stop gives a set of values E1, E2... E27 for the number of times each edge is traversed, and these values obey Kirchhoff's law, but are there solutions to Kirchhoff's equation that do not correspond to any computer program execution?  [gporadiod]
</p>
<p>Theorem K summarizes preceding discussion [pg 369].  [gipwdfqwq]
</p>
</p>

<h3>2.4 Multilinked Structures</h3>


<h3>2.5 Dynamic Storage Allocation</h3>

</div>
</body>
</html>
