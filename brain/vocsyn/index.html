<!DOCTYPE html>
<html lang="en">
<head>

<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<link rel="stylesheet" href="/brain/css/style.css">

</head>
<body>
<div id="main">
<title>Vocsyn</title>
<h1>Vocsyn</h1>
<p>Messages with the tag <code>vocsyn</code>, topics
related to vocal synthesis.
</p>
<p><b>[80327d94] 2022-11-25-15-15</b>: Imitation vs inspiration: a duality in the context of vocal synthesis. 
</p>
<p><b>[1905fdcb] 2022-11-25-15-15</b>: Articularity Synthesis: why invest time in such an unrealistic speech synthesis technique, when there are plenty of more modern approaches available? 
</p>
<p><b>[80cca442] 2022-11-25-15-15</b>: It comes down to philosophy: the voice is the seed of inspiration of music. Follow music through the perspective of th evoice. 
</p>
<p><b>[f93f821c] 2022-11-25-15-15</b>: It isn't a high objective to directly imitate or reproduce the human voice on the computer. Humans are pretty good at that already, and to me it's the wrong wheel to re-invent. 
</p>
<p><b>[cdd52689] 2022-11-25-15-15</b>: My singing synthesizers don't sing words, and I don't plan on adding them any time soon. It's not the point of it. The voice is simply the starting point in exploring lyrical control structures. 
</p>
<p><b>[37c269f4] 2022-11-25-15-15</b>: Why artic synthesis over other techniques (formant, concatenative, deep learning): malleability and control. Sculptability is quite desirable. It is a technique that wants to be playfully poked at. 
</p>
<p><b>[10023e1c] 2022-11-25-15-15</b>: The voice is a good instrument to model on a computer because it is a complex timbral instrument. There are many interesting challenges to solve regarding meaningful control. 
</p>
<p><b>[4f10380a] 2022-11-25-15-15</b>: Similar algorithms I've found in the same vein of articulatory synthesis as malleable timbre sources: FM Synthesis, morphing wavetables. The waveguide model of the voice is still the most inspiring (perhaps because it feels so relatable?) 
</p>
<p><b>[d0a697c9] 2022-10-07-08-21</b>: A Robotic Voice Simulator and the Interactive Training for Hearing-Impaired People <a href="https://www.hindawi.com/journals/bmri/2008/768232/">https://www.hindawi.com/journals/bmri/2008/768232/</a> 
</p>
<p><b>[c98bbe7c] 2022-07-02-08-43</b>: Making the Master System a Master of Speech <a href="https://nicole.express/2022/let-me-show-you-the-sound-of-m y-master.html">https://nicole.express/2022/let-me-show-you-the-sound-of-m y-master.html</a> 
</p>
<p><b>[e3e74e5a] 2022-06-29-06-24</b>: glance at lu/smith 1999 paper
</p>
<p><b>[39a94323] 2022-05-04-09-46</b>: HiFi-GAN is the underlying neural neural net used for speech synthesis in Larynx. <a href="https://github.com/jik876/hifi-gan">https://github.com/jik876/hifi-gan</a> 
</p>
<p><b>[931fab72] 2022-05-04-09-46</b>: Larynx is an end-to-end text to speech system. Wonder how hard it is to set up? <a href="https://github.com/rhasspy/larynx">https://github.com/rhasspy/larynx</a>. 
</p>
<p><b>[538a9df1] 2022-05-04-09-46</b>: A blog post on the speech synthesis technology employed by Casio. Contains some useful links. <a href="http://sandsoftwaresound.net/casio-speech-synthesis-technology/">http://sandsoftwaresound.net/casio-speech-synthesis-technology/</a>. 
</p>
<p><b>[ca21be66] 2022-05-04-09-46</b>: I believe this uses waveguides to produce cat sounds. Have not actually tried it, but I like the idea of it. <a href="https://experiments.withgoogle.com/feline-synth">https://experiments.withgoogle.com/feline-synth</a>. 
</p>
<p><b>[d828cef8] 2022-05-04-09-46</b>: An atari speech synthesizer for the AT2600. Could be worth studying and possibly adapting. <a href="https://github.com/rossumur/SAM2600">https://github.com/rossumur/SAM2600</a>. 
</p>
<p><b>[27c4edce] 2022-05-04-09-46</b>: Software Automatic Mouth: another implementation of SAM (I believe it's the same), based on speech software published in 1982 by Don't Ask Software. <a href="https://github.com/s-macke/SAM">https://github.com/s-macke/SAM</a> 
</p>
<p><b>[598a4049] 2022-05-04-09-46</b>: Chipseech by Plogue. A collection of vintage speech synthesizers. This product page has a bunch of useful information on it. <a href="https://plogue.com/products/chipspeech.html">https://plogue.com/products/chipspeech.html</a>. 
</p>
<p><b>[1e8e708a] 2022-04-05-15-50</b>: study gnuspeech TRM
</p>
<p><b>[84c8c21e] 2022-02-24-11-08</b>: this is apparently the reference used in praat's articulatory synthesizer. It seems very comprehensive and quite a bit more involved than the waveguides I've worked with.
</p>
<p><b>[7f017a2b] 2022-02-23-14-58</b>: this appears to be a CLM model of perry cook's vocal synthesizer: https://ccrma.stanford.edu/courses/220b-winter-2002/lectures/9/examples/singer.ins
</p>
<p><b>[3a9a6026] 2022-02-23-14-58</b>: vocsyn will be stuff related to vocal synthesis.
</p>
<p><b>[c0eef67b] 2021-12-21-20-07</b>: articulatory inversion: the process of taking acoustic data and converting it back into vocal tract shapes.
</p>
</div>
</body>
</html>
