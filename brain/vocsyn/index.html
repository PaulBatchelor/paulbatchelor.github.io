<!DOCTYPE html>
<html lang="en">
<head>

<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<link rel="stylesheet" href="/brain/css/style.css">

</head>
<body>
<div id="main">
<title>Vocsyn</title>
<h1>Vocsyn</h1>
<p>Messages with the tag <code>vocsyn</code>, topics
related to vocal synthesis.
</p>
<p><b>[c98bbe7c] 2022-07-02-08-43</b>: Making the Master System a Master of Speech <a href="https://nicole.express/2022/let-me-show-you-the-sound-of-m y-master.html">https://nicole.express/2022/let-me-show-you-the-sound-of-m y-master.html</a> 
</p>
<p><b>[e3e74e5a] 2022-06-29-06-24</b>: glance at lu/smith 1999 paper
</p>
<p><b>[39a94323] 2022-05-04-09-46</b>: HiFi-GAN is the underlying neural neural net used for speech synthesis in Larynx. <a href="https://github.com/jik876/hifi-gan">https://github.com/jik876/hifi-gan</a> 
</p>
<p><b>[931fab72] 2022-05-04-09-46</b>: Larynx is an end-to-end text to speech system. Wonder how hard it is to set up? <a href="https://github.com/rhasspy/larynx">https://github.com/rhasspy/larynx</a>. 
</p>
<p><b>[538a9df1] 2022-05-04-09-46</b>: A blog post on the speech synthesis technology employed by Casio. Contains some useful links. <a href="http://sandsoftwaresound.net/casio-speech-synthesis-technology/">http://sandsoftwaresound.net/casio-speech-synthesis-technology/</a>. 
</p>
<p><b>[ca21be66] 2022-05-04-09-46</b>: I believe this uses waveguides to produce cat sounds. Have not actually tried it, but I like the idea of it. <a href="https://experiments.withgoogle.com/feline-synth">https://experiments.withgoogle.com/feline-synth</a>. 
</p>
<p><b>[d828cef8] 2022-05-04-09-46</b>: An atari speech synthesizer for the AT2600. Could be worth studying and possibly adapting. <a href="https://github.com/rossumur/SAM2600">https://github.com/rossumur/SAM2600</a>. 
</p>
<p><b>[27c4edce] 2022-05-04-09-46</b>: Software Automatic Mouth: another implementation of SAM (I believe it's the same), based on speech software published in 1982 by Don't Ask Software. <a href="https://github.com/s-macke/SAM">https://github.com/s-macke/SAM</a> 
</p>
<p><b>[598a4049] 2022-05-04-09-46</b>: Chipseech by Plogue. A collection of vintage speech synthesizers. This product page has a bunch of useful information on it. <a href="https://plogue.com/products/chipspeech.html">https://plogue.com/products/chipspeech.html</a>. 
</p>
<p><b>[1e8e708a] 2022-04-05-15-50</b>: study gnuspeech TRM
</p>
<p><b>[84c8c21e] 2022-02-24-11-08</b>: this is apparently the reference used in praat's articulatory synthesizer. It seems very comprehensive and quite a bit more involved than the waveguides I've worked with.
</p>
<p><b>[7f017a2b] 2022-02-23-14-58</b>: this appears to be a CLM model of perry cook's vocal synthesizer: https://ccrma.stanford.edu/courses/220b-winter-2002/lectures/9/examples/singer.ins
</p>
<p><b>[3a9a6026] 2022-02-23-14-58</b>: vocsyn will be stuff related to vocal synthesis.
</p>
<p><b>[c0eef67b] 2021-12-21-20-07</b>: articulatory inversion: the process of taking acoustic data and converting it back into vocal tract shapes.
</p>
</div>
</body>
</html>
