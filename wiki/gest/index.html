<!DOCTYPE html>
<html lang="en">
<head>

<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<link rel="stylesheet" href="/css/style.css">

</head>
<body>
<div id="main">
<title>Gest</title>
<h1>Gest</h1>

<h2>Overview</h2>

<p>It all started with a <a href="/wiki/halfbaked">half baked idea</a>:
</p>
<p><blockquote>
<b>2020-07-29 17:19:40:</b> a music sequencer, but for producing continuous gestures instead of discrete steps. have it be clocked with an external source so it can play well with others. perhaps build a notation system around it. #halfbakedideas
</blockquote>
</p>
<p>Gest (pronounced "jest") is a sequencer for
gestures. Conceptually, it lies somewhere in between a
classic step sequencer and an automation curve editor.
</p>
<p>Timing in Gest is controlled via an external clock signal,
referred to as the <code>conductor</code> signal. The conductor signal
is expected to be a <code>phasor</code>: a periodic rising ramp signal
in range 0 and 1. Each period is considered as a musical
beat in time.
</p>
<p>Once instantiated with a conductor signal, Gest can then
be configured to produce <code>gestures</code>: audio-rate continuous
control signals intended to modulate synthesis parameters
(such as the frequency of an oscillator, or the cutoff of a
filter). Gestures are chunked into groups known as
<code>phrases</code>, which are blocked out to be a fixed duration
in units of beats.
</p>
<p>A phrase, once created, will analyze the conductor signal
and resynthesize a new slower signal by a factor of N beats,
where N is the duration of the phrase. This will produce a
single ramp from 0 to 1 that extends the duration of the
phrase. This particular operation is known as a <code>monoramp</code>.
This monoramp acts as a blank canvas for the phrase, and
can be equally divided up into an arbitrary number of
smaller ramps. This operation produces a <code>polyramp</code>.
Contiguous ramp segments in a polyramp can be merged
together into monoramps, and then divided into new
polyramps. This process produces a tree of ramps, known
as a <code>ramptree</code>.
</p>
<p>Every leaf node of a ramptree gets appended with a discrete
scalar value known as a <code>target</code>. Using the normalized
continuous values from the ramp tree, targets can be
interpolated together to produce line segments. The way
which a target gets to the next target is known as a
<code>behavior</code>.
</p>
<p>A behavior can be any function that takes in an alpha value,
and produce an output that involves two values A and B. It
is typically assumed that behaviors try to be contiguous:
when alpha is 0, the output should A. When alpha is 1, the
output should be B.
</p>
<p>Some examples of behaviors can include: linear, exponential,
step, and smoothstep.
</p>

<h2>Code and Documentation</h2>

<p>Code for Gest can be found on <code>sourcehut</code>:
<a href="https://git.sr.ht/~pbatch/gest">https://git.sr.ht/~pbatch/gest</a>.
</p>
<p>Gest is written as a <a href="/wiki/literate_programming">literate program</a> using <a href="/wiki/worgle">worgle</a>. The woven
output of this program can be found at
<a href="/loom/gest_program">gest_program</a>.
</p>
<p>In addition to the program itself, there is also a very
concise that aims to introduce the concepts of Gest, using
examples written in <a href="/wiki/sndkit">sndkit</a> via the
<a href="/wiki/LIL">LIL</a> scripting language. This can be found at
<a href="/loom/gest_guide">gest_guide</a>.
</p>

<h2>Updates</h2>

<p><blockquote>
<b>2021-07-17 12:43:01</b>: gest has been added to the (<a href="/wiki/loom">loom</a>) <a href="/loom/gest">gest</a>.
</p>
<p><b>2021-07-17 12:30:06</b>: guide pretty much written. things work well enough. migrating codebase to its own git repo. hoping to make an initial gest page for the (<a href="/wiki/loom">loom</a>) soon, containing the program and the guide.
</p>
<p><b>2021-07-15 18:36:40</b>: new milestone in (<a href="/wiki/gest">gest</a>): removed debug printf statements :)
</p>
<p><b>2021-07-15 09:22:36</b>: just merged all my test gestures together into one medley in (<a href="/wiki/gest">gest</a>) and it is quite satisfying.
</p>
<p><b>2021-07-14 22:25:33</b>: some initial work on temporal weights in (<a href="/wiki/gest">gest</a>). It's starting to tap into some (<a href="/wiki/howyousay">howyousay</a>) energy. I already got my example working with two interpretations on how to shape the tempo flucations.
</p>
<p><b>2021-07-14 16:13:44</b>: I'm thinking about writing a supplemental literate program consisting the program wrapped in a sndkit node, as well as a set of sample programs. This would all be published at the (<a href="/wiki/loom">loom</a>) eventually.
</p>
<p><b>2021-07-14 16:12:35</b>: things are actually working now in (<a href="/wiki/gest">gest</a>). woo! even the initial test examples I've made are inspiring.
</p>
<p><b>2021-07-13 11:29:01</b>: yeah, error accumulation is going to be something I'll need to focus on. I just turned on my naive solution and of course it doesn't work.
</p>
<p><b>2021-07-13 11:27:09</b>: lots of progress with my implementation. An initial ramptree with polyramps and targets with lineaer behavior works mostly. I'm running into some timing issues now, so there may need to be some better checking of time.
</p>
<p><b>2021-07-09 20:18:54</b>: hoping to spend this weekend working on (<a href="/wiki/gest">gest</a>). there's a lot to think about. words and some code have been written already these past two days.
</p>
<p><b>2021-06-26 18:09:51</b>: wrote some initial words down for what will be the gest program. slowly figuring out the implementation details.
</p>
<p><b>2021-06-24 09:25:31</b>: gave the (<a href="/wiki/gest">gest</a>) page an initial overview. it's a pretty good distillation of the concepts I have so far.
</p>
<p><b>2021-05-29 11:46:12</b>: I haven't figured out a convenient way to notate these gestures. Some sort of DSL probably. That's going to require some thought.
</p>
<p><b>2021-05-29 11:44:51</b>: these ramps would then be used as variables in sequencing generators for various interpolation methods to get from point A to point B.
</p>
<p><b>2021-05-29 11:43:24</b>: I have been basically imagining gestures being constructed out of a hierarchy of ramp signals generated from a phasor clock source. N number of phasor periods makes a single base ramp, which can be further subdivided into smaller ramps, which can be further subdivided, and so on.
</p>
<p><b>2021-05-29 11:39:58</b>: well, not arbitrary precision. it's floating point. but for rhythmic subdivision in music with room for microtimings, it's practically abritrary precision.
</p>
<p><b>2021-05-29 11:38:12</b>: phasors are pretty awesome because they contain continuous time data. It's pretty trivial to subdivide a phasor, and even scale it too. It's also very easy to turn phasors into clock signals with arbitrary precision.
</p>
<p><b>2021-05-29 11:34:55</b>: I was stuck for a while thinking how one could synchronize line generators with clock signals. Then I realized you could have a clock signal be a phasor instead of a tick signal like metro.
</p>
<p><b>2021-05-29 11:31:59</b>: it has been several months since I updated this page, but I've been thinking about this project off and on.
</p>
</blockquote>
<hr>
<p><a href="/wiki/">home</a> | <a href="/wiki/wiki_index">index</a></div>
</body>
</html>
